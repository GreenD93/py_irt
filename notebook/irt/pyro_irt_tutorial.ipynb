{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref - https://github.com/mfouesneau/NUTS\n",
    "\n",
    "\"\"\"\n",
    "it takes a series of steps informed by first-order gradient information. This feature allows it to converge much more quickly to high-dimensional target\n",
    "distributions compared to simpler methods such as Metropolis, Gibbs sampling (and derivatives).\n",
    "\n",
    "NUTS uses a recursive algorithm to find likely candidate points that automatically stops when it\n",
    "starts to double back and retrace its steps.  Empirically, NUTS perform at least as effciently as \n",
    "and sometimes more effciently than a well tuned standard HMC method, without requiring user intervention or costly tuning runs.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from irt.load_data import *\n",
    "from irt.irt_model import *\n",
    "\n",
    "dataset = load_1pl_simulation(num_person = 10000, num_item = 100, ability_dim = 1, nonlinear = False)\n",
    "train_dataset = load_dataset(train=True, num_person=10000, num_item=100, ability_dim=1, nonlinear=False, max_num_person=None, max_num_item=None)\n",
    "test_dataset = load_dataset(train=False, num_person=10000, num_item=100, ability_dim=1, nonlinear=False, max_num_person=None, max_num_item=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_item, num_person = train_dataset.num_item, train_dataset.num_person\n",
    "response, mask = train_dataset.response, train_dataset.mask\n",
    "\n",
    "response[response == -1] = 0  # filler value within support\n",
    "response = torch.from_numpy(response).float().to(device)\n",
    "mask = torch.from_numpy(mask).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer.mcmc.util import initialize_model, predictive\n",
    "\n",
    "\"\"\"\n",
    "Given a Python callable with Pyro primitives, generates the following model-specific\n",
    "properties needed for inference using HMC/NUTS kernels:\n",
    "\n",
    "- initial parameters to be sampled using a HMC kernel,\n",
    "- a potential function whose input is a dict of parameters in unconstrained space,\n",
    "- transforms to transform latent sites of `model` to unconstrained space,\n",
    "- a prototype trace to be used in MCMC to consume traces from sampled parameters.\n",
    "\"\"\"\n",
    "\n",
    "irt_model = irt_model_1pl\n",
    "\n",
    "init_params, potential_fn, transforms, _ = initialize_model(\n",
    "        irt_model,\n",
    "        model_args=(\n",
    "            1, \n",
    "            num_person, \n",
    "            num_item, \n",
    "            device, \n",
    "            response, \n",
    "            mask, \n",
    "            1,\n",
    "        ),\n",
    "        num_chains=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 300/300 [00:45,  6.56it/s, step size=1.46e-01, acc. prob=0.868]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer.mcmc import NUTS\n",
    "from pyro.infer.mcmc.api import MCMC\n",
    "\n",
    "ability_dim = 1\n",
    "num_samples = 200\n",
    "num_warmup = 100\n",
    "num_chains = 1\n",
    "\n",
    "nuts_kernel = NUTS(potential_fn = potential_fn)\n",
    "\n",
    "mcmc = MCMC(\n",
    "    nuts_kernel,\n",
    "    num_samples = num_samples,\n",
    "    warmup_steps = num_warmup,\n",
    "    num_chains = num_chains,\n",
    "    initial_params = init_params,\n",
    "    transforms = transforms,\n",
    ")\n",
    "\n",
    "# same irt model input param\n",
    "mcmc.run(\n",
    "    ability_dim, \n",
    "    num_person, \n",
    "    num_item, \n",
    "    device, \n",
    "    response, \n",
    "    mask, \n",
    "    1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ability : (샘플수, 사람수, 1)\n",
    "# item_feat : (샘플수, 문항수, 1)\n",
    "\n",
    "samples = mcmc.get_samples()\n",
    "for key in samples.keys():\n",
    "    samples[key] = samples[key].cpu()\n",
    "    \n",
    "sample_means, sample_variances = {}, {}\n",
    "for key, sample in samples.items():\n",
    "    sample_means[key] = torch.mean(samples[key], dim=0)\n",
    "    sample_variances[key] = torch.var(samples[key], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8000, 1])\n",
      "torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "print(sample_means['ability'].shape)\n",
    "print(sample_means['item_feat'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.8/site-packages/pyro/infer/mcmc/util.py:590: FutureWarning: The `mcmc.predictive` function is deprecated and will be removed in a future release. Use the `pyro.infer.Predictive` class instead.\n",
      "  warnings.warn('The `mcmc.predictive` function is deprecated and will be removed in '\n"
     ]
    }
   ],
   "source": [
    "from pyro.util import ignore_experimental_warning\n",
    "\n",
    "def sample_posterior_predictive(model, posterior_samples, *args):\n",
    "    with ignore_experimental_warning():\n",
    "        predict = predictive(model, posterior_samples, *args)\n",
    "        return predict\n",
    "    \n",
    "# get posterior predictive samples (response)\n",
    "posterior_predict_samples = sample_posterior_predictive(\n",
    "    irt_model, \n",
    "    samples, \n",
    "    ability_dim, \n",
    "    num_person, \n",
    "    num_item, \n",
    "    device,\n",
    "    None, \n",
    "    None, \n",
    "    1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 8000, 100, 1])\n"
     ]
    }
   ],
   "source": [
    "print(posterior_predict_samples['response'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
